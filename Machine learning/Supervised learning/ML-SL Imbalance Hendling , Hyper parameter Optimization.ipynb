{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbdbe865-a6fa-4ee6-ac17-339779b440da",
   "metadata": {},
   "source": [
    "# Machine Learning - Supervised Learning\n",
    "\n",
    "## Imbalance Data Handling\n",
    "\n",
    "* Class imbalance is a common problem in machine learning, where the number of instances in each class is not equally distributed. This imbalance can lead to poor performance of the model, especially for the minority class. Here are some techniques to handle class imbalance:\n",
    "\n",
    "### Resampling Techniques\n",
    "* **Oversampling**: Increase the number of instances in the minority class.\n",
    "\n",
    "    * **Random Oversampling**: Randomly replicate minority class instances.\n",
    "    * **SMOTE (Synthetic Minority Over-sampling Technique)**: Generate synthetic instances by interpolating between existing minority class instances.\n",
    "* Undersampling: Reduce the number of instances in the majority class.\n",
    "\n",
    "    * **Random Undersampling(+**: Randomly remove majority class instances.\n",
    "    * **Cluster Centroids**: Use clustering techniques to reduce the majority class by averaging points in clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3901d0-b91d-46f4-bab6-0dc038305b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "# import pip\n",
    "# pip.main([\"install\", \"imblearn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29497867-5c5e-4a19-85ac-95d0f94026b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  duration  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  \\\n",
      "0   44       210           1.4          93.444          -36.1      4.963   \n",
      "1   53       138          -0.1          93.200          -42.0      4.021   \n",
      "2   28       339          -1.7          94.055          -39.8      0.729   \n",
      "3   39       185          -1.8          93.075          -47.1      1.405   \n",
      "4   55       137          -2.9          92.201          -31.4      0.869   \n",
      "\n",
      "   nr_employed  y  \n",
      "0       5228.1  1  \n",
      "1       5195.8  1  \n",
      "2       4991.6  1  \n",
      "3       5099.1  1  \n",
      "4       5076.2  1  \n"
     ]
    }
   ],
   "source": [
    "my_data = pd.read_csv(\"Bank_Imbalance.csv\")\n",
    "print(my_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54db8ba5-3166-49f7-ada9-e530df5b42b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = my_data.iloc[ : , : 7]\n",
    "y = my_data.iloc[ : , 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f43ec7-15a5-4b09-b10e-f75965b7927e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "1    2396\n",
       "0     603\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8009a1e-832c-4b77-ad41-750421ee3157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f878ee6-4398-4fa5-a808-258a85a84d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "1    79.893298\n",
       "0    20.106702\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y.value_counts()/y.value_counts().sum() ) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56002d3f-f086-42a8-8b33-ac93e4f7821c",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "\n",
    "* SMOTE (Synthetic Minority Over-sampling Technique) is a widely used technique to address class imbalance in datasets. SMOTE works by generating synthetic samples for the minority class. It does this by selecting samples that are close to each other in the feature space, drawing a line between the samples in feature space, and creating new samples along this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1ba87a9-6efd-478f-9bc1-144c8c41c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c92b5f8-a692-4194-a4b7-aaf83bf465f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_smote, y_smote = smt.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60843aea-72bc-448b-8302-2ac7c5e0d533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "1    2396\n",
       "0    2396\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smote.value_counts() # There are newly generated  0 points previosly we had 603 but now 2396 same as 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e543f6b3-5d83-46f1-8232-c9e6dbf90129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 7)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00f6aaa5-fcfb-46e8-8d1d-d9ec667209dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4792, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_smote.shape # shape was  updated due to overesampeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e4afd-1d06-4764-be0b-0db04f5bf88d",
   "metadata": {},
   "source": [
    "### ADASYN\n",
    "\n",
    "* ADASYN (Adaptive Synthetic Sampling Approach) is an advanced oversampling technique used to handle class imbalance in datasets. It is an improvement over the SMOTE (Synthetic Minority Over-sampling Technique) method. ADASYN generates synthetic data points for the minority class, focusing more on difficult-to-learn examples that are near the boundary of the decision region, which helps in improving classifier performance.\n",
    "\n",
    "* How ADASYN Works\n",
    "    * **Identify Difficult Sample**s: It identifies minority class samples that are difficult to classify.\n",
    "    * **Generate Synthetic Samples**: It generates synthetic samples for the minority class, giving more weight to samples that are harder to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0510d6a9-2aed-4c0a-a279-6a8bf7d59933",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = ADASYN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40c6a0ba-4b27-4869-9b74-5b51f0fee677",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ads, y_ads = ads.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86df0c0b-8350-4df5-938f-a0a07b1be769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    2404\n",
       "1    2396\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ads.value_counts()   # Now balance but not same as SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290c455-d0bf-4097-b783-79d227b59e78",
   "metadata": {},
   "source": [
    "# Hyper Parameter Optimization\n",
    "\n",
    "* Hyperparameter optimization is the process of finding the best set of hyperparameters for a machine learning model. The goal is to identify the combination of hyperparameters that results in the best performance of the model, typically measured by some validation metric.\n",
    "\n",
    "Methods of Hyperparameter Optimization:\n",
    "\n",
    "**1) Grid Search**:\n",
    "\n",
    "* A systematic way of working through multiple combinations of hyperparameter values, specified in a grid.\n",
    "* The model is evaluated for each combination using cross-validation.\n",
    "\n",
    "**2) Random Search**:\n",
    "\n",
    "* Instead of trying all combinations, it randomly samples from the hyperparameter space.\n",
    "* Can be more efficient than grid search for large parameter spaces.\n",
    "\n",
    "**3) Bayesian Optimization**:\n",
    "\n",
    "* Uses a probabilistic model to predict the performance of different hyperparameter combinations.\n",
    "* More efficient by focusing on promising areas of the hyperparameter space.\n",
    "  \n",
    "Tools:\n",
    "\n",
    "* Hyperopt\n",
    "* BayesianOptimization\n",
    "  \n",
    "**4) Genetic Algorithms**:\n",
    "\n",
    "* Inspired by the process of natural selection.\n",
    "* Combines exploration and exploitation by iteratively selecting, recombining, and mutating a population of hyperparameter combinations.\n",
    "\n",
    "Tools:\n",
    "\n",
    "* TPOT\n",
    "* DEAP\n",
    "  \n",
    "**5) Gradient-based Optimization**:\n",
    "\n",
    "* Uses gradients to optimize hyperparameters.\n",
    "* Suitable for differentiable hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495efe39-a8d3-44ba-a52f-c382f2817d5e",
   "metadata": {},
   "source": [
    "## Grid \n",
    "* when we have two hyper perameters we have to use comBination(couple) of them\n",
    "* EX: a = 1, 2, 3   b = 10, 20, ---> (1, 10) or (1, 20) or (2, 10) or ... (3, 20) Then all of these are separately apply and find validation choose a combination which having minimum cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d7524b9-46a0-4185-8114-78353f62c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold # \"KFold\" technique is used for cross validation\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161d7411-717f-464d-bdb7-308959d84627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hyper = pd.read_csv(\"Boston.csv\")\n",
    "data_hyper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75d2d5a9-5ecd-4111-837b-0109d1bf2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_hyper.iloc[:, :12].values\n",
    "y = data_hyper.iloc[:, 12].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fdc720a-e214-4bd9-b585-7c1d7f6f0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6359c46-92f1-4fa1-af8e-23359dcfef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_s = {\"n_neighbors\": [1,2,3,4,5,6,7,8,9,10]} # single hypper parameter\n",
    "model = KNeighborsRegressor()\n",
    "c_vals = KFold(n_splits= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "541b4477-fb96-4351-a971-9b44421e9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch = GridSearchCV( model, param_s, cv = c_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f2d3360-aa37-448b-aa94-d04c54f6702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gsearch.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09014202-53de-422b-bb63-1a235ef13ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_params_ # we dont want to do anything manually algorithm does(in cross_val_score ,we must do something to find best value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500f19e-2b75-4e2d-89d9-005626995bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
